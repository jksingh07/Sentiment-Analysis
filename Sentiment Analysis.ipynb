{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d7b1c9",
   "metadata": {},
   "source": [
    "## Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0eaf51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dash-bootstrap-components\n",
      "  Downloading dash_bootstrap_components-1.4.1-py3-none-any.whl (220 kB)\n",
      "\u001b[K     |████████████████████████████████| 220 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dash>=2.0.0\n",
      "  Downloading dash-2.9.1-py3-none-any.whl (10.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.2 MB 72.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: plotly>=5.0.0 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash-bootstrap-components) (5.6.0)\n",
      "Requirement already satisfied: Flask>=1.0.4 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash-bootstrap-components) (1.1.2)\n",
      "Collecting dash-core-components==2.0.0\n",
      "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting dash-table==5.0.0\n",
      "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Collecting dash-html-components==2.0.0\n",
      "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from Flask>=1.0.4->dash>=2.0.0->dash-bootstrap-components) (2.0.1)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from Flask>=1.0.4->dash>=2.0.0->dash-bootstrap-components) (2.0.3)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from Flask>=1.0.4->dash>=2.0.0->dash-bootstrap-components) (2.11.3)\n",
      "Requirement already satisfied: click>=5.1 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from Flask>=1.0.4->dash>=2.0.0->dash-bootstrap-components) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from Jinja2>=2.10.1->Flask>=1.0.4->dash>=2.0.0->dash-bootstrap-components) (2.0.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from plotly>=5.0.0->dash>=2.0.0->dash-bootstrap-components) (8.0.1)\n",
      "Requirement already satisfied: six in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from plotly>=5.0.0->dash>=2.0.0->dash-bootstrap-components) (1.16.0)\n",
      "Installing collected packages: dash-table, dash-html-components, dash-core-components, dash, dash-bootstrap-components\n",
      "Successfully installed dash-2.9.1 dash-bootstrap-components-1.4.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dash-bootstrap-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113a9622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from vaderSentiment) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2021.10.8)\n",
      "Requirement already satisfied: textblob in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: click in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: tqdm in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2022.3.15)\n",
      "Requirement already satisfied: joblib in /Users/jaskaransingh/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment\n",
    "!pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98df37b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1af511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6b7c884",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c27587b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textblob\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b30b58b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/jaskaransingh/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69e9ff63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jaskaransingh/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "941ea75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/jaskaransingh/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jaskaransingh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jaskaransingh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jaskaransingh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     /Users/jaskaransingh/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/jaskaransingh/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d97b1f8",
   "metadata": {},
   "source": [
    "## Exploring TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "309aae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = TextBlob(\"Hey, Exploring TextBlob today, it's an awesome library for NLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2ae9254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_cmpkey',\n",
       " '_compare',\n",
       " '_create_sentence_objects',\n",
       " '_strkey',\n",
       " 'analyzer',\n",
       " 'classifier',\n",
       " 'classify',\n",
       " 'correct',\n",
       " 'detect_language',\n",
       " 'ends_with',\n",
       " 'endswith',\n",
       " 'find',\n",
       " 'format',\n",
       " 'index',\n",
       " 'join',\n",
       " 'json',\n",
       " 'lower',\n",
       " 'ngrams',\n",
       " 'noun_phrases',\n",
       " 'np_counts',\n",
       " 'np_extractor',\n",
       " 'parse',\n",
       " 'parser',\n",
       " 'polarity',\n",
       " 'pos_tagger',\n",
       " 'pos_tags',\n",
       " 'raw',\n",
       " 'raw_sentences',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'sentences',\n",
       " 'sentiment',\n",
       " 'sentiment_assessments',\n",
       " 'serialized',\n",
       " 'split',\n",
       " 'starts_with',\n",
       " 'startswith',\n",
       " 'string',\n",
       " 'strip',\n",
       " 'stripped',\n",
       " 'subjectivity',\n",
       " 'tags',\n",
       " 'title',\n",
       " 'to_json',\n",
       " 'tokenize',\n",
       " 'tokenizer',\n",
       " 'tokens',\n",
       " 'translate',\n",
       " 'translator',\n",
       " 'upper',\n",
       " 'word_counts',\n",
       " 'words']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(analyser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2d76218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Hey', ',', 'Exploring', 'TextBlob', 'today', ',', 'it', \"'s\", 'an', 'awesome', 'library', 'for', 'NLP'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8c06840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Hey', 'Exploring', 'TextBlob']),\n",
       " WordList(['Exploring', 'TextBlob', 'today']),\n",
       " WordList(['TextBlob', 'today', 'it']),\n",
       " WordList(['today', 'it', \"'s\"]),\n",
       " WordList(['it', \"'s\", 'an']),\n",
       " WordList([\"'s\", 'an', 'awesome']),\n",
       " WordList(['an', 'awesome', 'library']),\n",
       " WordList(['awesome', 'library', 'for']),\n",
       " WordList(['library', 'for', 'NLP'])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.ngrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2b2074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object ` analyser.translate()` not found.\n"
     ]
    }
   ],
   "source": [
    "analyser.translate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1d7ed87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hey', 'NNP'),\n",
       " ('Exploring', 'NNP'),\n",
       " ('TextBlob', 'NNP'),\n",
       " ('today', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('an', 'DT'),\n",
       " ('awesome', 'JJ'),\n",
       " ('library', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('NLP', 'NNP')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check POS tags\n",
    "analyser.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c46118ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अरे, TextBlob की खोज आज, यह NLP के लिए एक भयानक पुस्तकालय है\n"
     ]
    }
   ],
   "source": [
    "# TRANSLATION USING TEXTBLOB\n",
    "\n",
    "print(analyser.translate(from_lang='en', to='hi')) # Translate to Hindi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea4176e",
   "metadata": {},
   "source": [
    "### Subjectivity and Polarity\n",
    "\n",
    "TextBlob returns polarity and subjectivity of a sentence. Polarity lies between [-1,1], -1 defines a negative sentiment and 1 defines a positive sentiment. Negation words reverse the polarity. TextBlob has semantic labels that help with fine-grained analysis. For example — emoticons, exclamation mark, emojis, etc. Subjectivity lies between [0,1]. Subjectivity quantifies the amount of personal opinion and factual information contained in the text. The higher subjectivity means that the text contains personal opinion rather than factual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6443870c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=1.0, subjectivity=1.0)\n",
      "Sentiment(polarity=1.0, subjectivity=1.0, assessments=[(['awesome'], 1.0, 1.0, None)])\n"
     ]
    }
   ],
   "source": [
    "# To check the sentiments -> returns 2 values \n",
    "# 1. polarity( range -1 to 1, -1=-ve, 1=+ve sentiments) and \n",
    "# 2. subjectivity (range 0-1, how much subjective or objective the content is)\n",
    "\n",
    "print(analyser.sentiment)\n",
    "print(analyser.sentiment_assessments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7661586",
   "metadata": {},
   "source": [
    "### Analysing Sentiments (+ve and -ve) on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9da062d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Correct Positive lines = 3790, Total line = 3790\n"
     ]
    }
   ],
   "source": [
    "positive_true =0\n",
    "positive_count = 0\n",
    "\n",
    "with open('positive.txt', 'r', encoding='latin-1') as f:\n",
    "    for line in f:\n",
    "        blob = TextBlob(line)\n",
    "        if blob.sentiment.polarity > 0.0001:\n",
    "            if blob.sentiment.polarity > 0:\n",
    "                positive_true += 1\n",
    "            positive_count += 1\n",
    "print(f' Correct Positive lines = {positive_true}, Total line = {positive_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "50cabb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Correct negative lines = 2978, Total line = 2986\n"
     ]
    }
   ],
   "source": [
    "negative_true =0\n",
    "negative_count = 0\n",
    "\n",
    "with open('negative.txt', 'r', encoding='latin-1') as f:\n",
    "    for line in f:\n",
    "        blob = TextBlob(line)\n",
    "        if blob.sentiment.polarity < 0.0001:\n",
    "            if blob.sentiment.polarity <= 0:\n",
    "                negative_true += 1\n",
    "            negative_count += 1\n",
    "print(f' Correct negative lines = {negative_true}, Total line = {negative_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "81616053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Accuracy = 100.0, Total Lines used: 3790\n",
      "Negative Accuracy = 99.73208305425318, Total Lines used: 2986\n"
     ]
    }
   ],
   "source": [
    "print(f'Positive Accuracy = {(positive_true / positive_count)*100}, Total Lines used: {positive_count}')\n",
    "print(f'Negative Accuracy = {(negative_true / negative_count)*100}, Total Lines used: {negative_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97539174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e1835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25d80bc5",
   "metadata": {},
   "source": [
    "## Exploting Vader Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd809766",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2f619a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = analyser.polarity_scores(\"Exploring Vader Sentiment which can perform better than TextBlob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "71b3f394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.734, 'pos': 0.266, 'compound': 0.4404}\n"
     ]
    }
   ],
   "source": [
    "print(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d9573b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Correct Positive lines = 2323, Total line = 2650\n"
     ]
    }
   ],
   "source": [
    "positive_true =0\n",
    "positive_count = 0\n",
    "threshold = 0.5\n",
    "\n",
    "with open('positive.txt', 'r', encoding='latin-1') as f:\n",
    "    for line in f:\n",
    "        vs = analyser.polarity_scores(line)\n",
    "        if vs['compound'] >=threshold or vs['compound']<= -threshold:\n",
    "            if vs['compound'] > 0.5:\n",
    "                positive_true += 1\n",
    "            positive_count += 1\n",
    "print(f' Correct Positive lines = {positive_true}, Total line = {positive_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "89ef40bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Correct negative lines = 904, Total line = 1824\n"
     ]
    }
   ],
   "source": [
    "negative_true =0\n",
    "negative_count = 0\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "with open('negative.txt', 'r', encoding='latin-1') as f:\n",
    "    for line in f:\n",
    "        vs = analyser.polarity_scores(line)\n",
    "        if vs['compound'] >=threshold or vs['compound']<= -threshold:\n",
    "            if vs['compound'] <= 0:\n",
    "                negative_true += 1\n",
    "            negative_count += 1\n",
    "print(f' Correct negative lines = {negative_true}, Total line = {negative_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cc802356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Accuracy = 87.66037735849056, Total Lines used: 2650\n",
      "Negative Accuracy = 49.56140350877193, Total Lines used: 1824\n"
     ]
    }
   ],
   "source": [
    "print(f'Positive Accuracy = {(positive_true / positive_count)*100}, Total Lines used: {positive_count}')\n",
    "print(f'Negative Accuracy = {(negative_true / negative_count)*100}, Total Lines used: {negative_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6334e720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "05c0a65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Correct Positive lines = 3319, Total line = 4096\n"
     ]
    }
   ],
   "source": [
    "# MORE EFFICIENT\n",
    "\n",
    "positive_true =0\n",
    "positive_count = 0\n",
    "\n",
    "with open('positive.txt', 'r', encoding='latin-1') as f:\n",
    "    for line in f:\n",
    "        vs = analyser.polarity_scores(line)\n",
    "        if not vs['neg'] > 0.1:\n",
    "            if vs['pos'] - vs['neg'] > 0:\n",
    "                positive_true += 1\n",
    "            positive_count += 1\n",
    "print(f' Correct Positive lines = {positive_true}, Total line = {positive_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6a48fff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Correct negative lines = 2612, Total line = 2925\n"
     ]
    }
   ],
   "source": [
    "negative_true =0\n",
    "negative_count = 0\n",
    "\n",
    "\n",
    "\n",
    "with open('negative.txt', 'r', encoding='latin-1') as f:\n",
    "    for line in f:\n",
    "        vs = analyser.polarity_scores(line)\n",
    "        if not vs['pos'] > 0.1:\n",
    "            if vs['neg']- vs['pos'] >= 0:\n",
    "                negative_true += 1\n",
    "            negative_count += 1\n",
    "print(f' Correct negative lines = {negative_true}, Total line = {negative_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f1a09b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Accuracy = 81.0302734375, Total Lines used: 4096\n",
      "Negative Accuracy = 89.2991452991453, Total Lines used: 2925\n"
     ]
    }
   ],
   "source": [
    "print(f'Positive Accuracy = {(positive_true / positive_count)*100}, Total Lines used: {positive_count}')\n",
    "print(f'Negative Accuracy = {(negative_true / negative_count)*100}, Total Lines used: {negative_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f47d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
